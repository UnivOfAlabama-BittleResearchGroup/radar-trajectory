{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "import utm\n",
    "\n",
    "from filtering import Filtering\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.scan_parquet(\n",
    "    \"/Users/max/Library/CloudStorage/Box-Box/Radar-Data/1677797903256.parquet\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the object id & sort by time\n",
    "df = df.with_columns(\n",
    "    [\n",
    "        (pl.col(\"ui32_objectID\").cast(str) + \"_\" + pl.col(\"ip\")).alias(\"object_id\"),\n",
    "    ]\n",
    ").sort(\"epoch_time\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resample the Radar Data to Every .15 Seconds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "GROUPBY_EVERY = \"100ms\"\n",
    "\n",
    "df = df.sort(\"epoch_time\").groupby_dynamic(\n",
    "    index_column=\"epoch_time\",\n",
    "    every=GROUPBY_EVERY,\n",
    "    by=[\"object_id\"],\n",
    ").agg(\n",
    "    [\n",
    "        pl.col('f32_positionX_m').mean(),\n",
    "        pl.col('f32_positionY_m').mean(),\n",
    "        pl.col(\"f32_velocityInDir_mps\").mean(),\n",
    "        # take the first value of the rest of the columns\n",
    "        *(\n",
    "            pl.col(col).first()\n",
    "            for col in df.columns\n",
    "            if col not in [\"f32_positionX_m\", \"f32_positionY_m\", \"f32_velocityInDir_mps\", \"object_id\", \"epoch_time\"]\n",
    "        ),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Remove Objects that don't move atleast 10 meters or spend < 10 seconds on the radar"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geolocate the Radar Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the file paths\n",
    "network_outline_file = \"./geo_data/network_outline.geojson\"\n",
    "radar_locations_file = \"./geo_data/radar_origins.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = Filtering(\n",
    "    radar_location_path=radar_locations_file,\n",
    "    network_boundary_path=network_outline_file,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function: radar_to_utm took: 0.2780170440673828 seconds\n",
      "function: radar_to_latlon took: 0.1320507526397705 seconds\n",
      "function: radar_to_h3 took: 0.9018926620483398 seconds\n",
      "function: filter_network_boundaries took: 0.05010628700256348 seconds\n"
     ]
    }
   ],
   "source": [
    "df = (\n",
    "    df.pipe(f.radar_to_utm)\n",
    "    .pipe(f.radar_to_latlon)\n",
    "    .pipe(f.radar_to_h3)\n",
    "    .pipe(f.filter_network_boundaries)\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatically Find the Regions of Overlapping Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "overlaps = df.groupby(['h3', 'ip']).agg([\n",
    "    pl.col('object_id').count().alias('count'),\n",
    "]).pivot(values='count', index='h3', columns='ip', aggregate_function='sum').fill_null(0).to_pandas().set_index('h3')\n",
    "\n",
    "# divide each row by its sum\n",
    "overlaps = overlaps.div(overlaps.sum(axis=1), axis=0)\n",
    "\n",
    "\n",
    "# overlaps.to_csv('overlaps.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Overlap Zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "AIRPORT = '10.160.7.136', '10.160.7.137'\n",
    "LOWES = \"10.160.7.141\", \"10.160.7.142\"\n",
    "HARPER =\"10.160.7.146\", \"10.160.7.147\"\n",
    "\n",
    "overlapping_pairs = (\n",
    "    (AIRPORT[1], LOWES[0]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a set of h3 corresponding to the overlapping pairs\n",
    "THRESHOLD = 0.05\n",
    "\n",
    "overlapping_h3 = {\n",
    "    pair: list(set(overlaps.loc[overlaps[pair[0]] > THRESHOLD].index)\n",
    "    & set(overlaps.loc[overlaps[pair[1]] > THRESHOLD].index))\n",
    "    for pair in overlapping_pairs\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Pair\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pair = overlapping_pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_df = df.filter(pl.col('h3').is_in(overlapping_h3[test_pair]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_1_df = df.filter(pl.col('ip') == test_pair[0])\n",
    "ip_2_df = df.filter(pl.col('ip') == test_pair[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches_ip1 = {}\n",
    "\n",
    "for veh in ip_1_df['object_id'].unique().to_list():\n",
    "    if ip_1_df.filter(pl.col('object_id') == veh).select(['epoch_time', 'h3']).join(\n",
    "       ip_2_df,\n",
    "        on=['epoch_time', 'h3'],\n",
    "        ).shape[0] > 1:\n",
    "        \n",
    "            match_df = ip_1_df.filter(pl.col('object_id') == veh).select(['epoch_time', 'h3']).join(\n",
    "                ip_2_df,\n",
    "                on=['epoch_time', 'h3'],\n",
    "            )\n",
    "\n",
    "            matches = match_df.groupby('object_id').agg([\n",
    "                pl.col('epoch_time').count().alias('count'),\n",
    "            ]).sort('count', descending=True).to_numpy()\n",
    "\n",
    "            # if len(matches) > 1:\n",
    "            #     break\n",
    "            \n",
    "            matches_ip1[veh] = matches[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(658, 192)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ip_1_df['object_id'].unique().to_list()), len(matches_ip1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'61809_10.160.7.141'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_df = ip_1_df.filter(pl.col('object_id') == veh).select(['epoch_time', 'h3']).join(\n",
    "    ip_2_df,\n",
    "    on=['epoch_time', 'h3'],\n",
    ")\n",
    "\n",
    "match_df.groupby('object_id').agg([\n",
    "    pl.col('epoch_time').count().alias('count'),\n",
    "]).sort('count', descending=True).to_numpy()[0][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Distance to TL1 Stop Bar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.utm_zone[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TL1_POS = (33.233039472986604, -87.62266063800959)\n",
    "TL1_POS_UTM = utm.from_latlon(\n",
    "    *TL1_POS, force_zone_number=f.utm_zone[0], force_zone_letter=f.utm_zone[1]\n",
    ")[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.with_columns(\n",
    "    [\n",
    "        (\n",
    "            ((pl.col(\"x\") - TL1_POS_UTM[0]) ** 2 + (pl.col(\"y\") - TL1_POS_UTM[1]) ** 2)\n",
    "            ** 0.5\n",
    "        ).alias(\"distance_from_tl1\"),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grab two Simlar Trajectories\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veh1 = \"62249_10.160.7.141\"\n",
    "veh2 = \"46656_10.160.7.137\"\n",
    "veh3 = \"62252_10.160.7.141\"\n",
    "## get the data for the two vehicles\n",
    "df1 = df.filter(pl.col(\"object_id\") == veh1).to_pandas()\n",
    "df2 = df.filter(pl.col(\"object_id\") == veh2).to_pandas()\n",
    "# only consider objects that move closer to TL1 during their time in the network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df1[['epoch_time', 'h3']].apply(tuple, axis=1)) & set(df2[['epoch_time', 'h3']].apply(tuple, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "keep_ips = [\n",
    "    \"10.160.7.136\",\n",
    "    \"10.160.7.137\",\n",
    "    \"10.160.7.141\",\n",
    "    \"10.160.7.142\",\n",
    "    \"10.160.7.146\",\n",
    "    \"10.160.7.147\",\n",
    "]\n",
    "\n",
    "\n",
    "radar_ips = df[\"ip\"].unique().to_list()\n",
    "radar_colors = px.colors.qualitative.D3\n",
    "radar_color_map = {\n",
    "    ip: radar_colors[i % len(radar_colors)] for i, ip in enumerate(radar_ips)\n",
    "}\n",
    "\n",
    "plotted_ips = set()\n",
    "for veh in [veh1, veh2, veh3]:\n",
    "    _df = df.filter(pl.col(\"object_id\") == veh).to_pandas()\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=_df.epoch_time,\n",
    "            y=_df.distance_from_tl1,\n",
    "            mode=\"lines\",\n",
    "            opacity=1,\n",
    "            line_color=radar_color_map[_df.ip.iloc[0]],\n",
    "            name=_df.ip.iloc[0],\n",
    "            showlegend=True,\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "keep_ips = [\n",
    "    \"10.160.7.136\",\n",
    "    \"10.160.7.137\",\n",
    "    \"10.160.7.141\",\n",
    "    \"10.160.7.142\",\n",
    "    \"10.160.7.146\",\n",
    "    \"10.160.7.147\",\n",
    "]\n",
    "\n",
    "\n",
    "radar_ips = df[\"ip\"].unique().to_list()\n",
    "radar_colors = px.colors.qualitative.D3\n",
    "radar_color_map = {\n",
    "    ip: radar_colors[i % len(radar_colors)] for i, ip in enumerate(radar_ips)\n",
    "}\n",
    "\n",
    "plotted_ips = set()\n",
    "for veh in [veh1, veh2, veh3]:\n",
    "    _df = df.filter(pl.col(\"object_id\") == veh).to_pandas()\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=_df.x,\n",
    "            y=_df.y,\n",
    "            mode=\"lines\",\n",
    "            opacity=1,\n",
    "            line_color=radar_color_map[_df.ip.iloc[0]],\n",
    "            name=_df.ip.iloc[0],\n",
    "            showlegend=True,\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try the Trajectory Association Methods\n",
    "\n",
    "Following https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=4635697\n",
    "\n",
    "1. Subtract the first moment of the trajectory from itself\n",
    "2. Fit a 2nd order polynomial to the trajectory\n",
    "3. Take the absolute difference between the start and end position of the trajectories IN THE OVERLAPPING REGION\n",
    "4. They drop the time vector....\n",
    "\n",
    "Following https://www.eecs.qmul.ac.uk/~andrea/papers/2009_AVSS_TrajAssociation_Anjum_Cavallaro.pdf\n",
    "\n",
    "1. They add the average velocity to above\n",
    "2. They add the average position to above\n",
    "3. They do a histogram function of direction angles to find the three dominant angles of the trajectory\n",
    "\n",
    "Both create a vector of these features for each trajectory and then calculate the correlation between all of the trajectories, taking the max as the match\n",
    "\n",
    "**Problems: They do not consider time at all? Nevermind, it is baked into the polynomial regression**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Overlapping Region\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get only trajectories that are inside of the overlapping box\n",
    "import geopandas as gpd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_df = gpd.read_file(\"overlap_zones/141_137.geojson\")\n",
    "\n",
    "# convert to utm\n",
    "box_df = box_df.to_crs(box_df.estimate_utm_crs())\n",
    "\n",
    "# convert from multilinestring to polygon\n",
    "box_df[\"geometry\"] = box_df[\"geometry\"].convex_hull\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_ips = [\"10.160.7.141\", \"10.160.7.137\"]\n",
    "\n",
    "\n",
    "sliced = df.filter(pl.col(\"ip\").is_in(keep_ips)).to_pandas()\n",
    "\n",
    "radar_df = gpd.GeoDataFrame(\n",
    "    sliced, geometry=gpd.points_from_xy(sliced.x, sliced.y), crs=box_df.crs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection_df = radar_df.loc[radar_df.geometry.intersects(box_df.geometry.iloc[0])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "keep_ips = [\n",
    "    \"10.160.7.136\",\n",
    "    \"10.160.7.137\",\n",
    "    \"10.160.7.141\",\n",
    "    \"10.160.7.142\",\n",
    "    \"10.160.7.146\",\n",
    "    \"10.160.7.147\",\n",
    "]\n",
    "\n",
    "\n",
    "radar_ips = df[\"ip\"].unique().to_list()\n",
    "radar_colors = px.colors.qualitative.D3\n",
    "radar_color_map = {\n",
    "    ip: radar_colors[i % len(radar_colors)] for i, ip in enumerate(radar_ips)\n",
    "}\n",
    "\n",
    "plotted_ips = set()\n",
    "for veh in [veh1, veh2, veh3]:\n",
    "    _df = intersection_df.loc[intersection_df[\"object_id\"] == veh]\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=_df.epoch_time,\n",
    "            y=_df.distance_from_tl1,\n",
    "            mode=\"lines\",\n",
    "            opacity=1,\n",
    "            line_color=radar_color_map[_df.ip.iloc[0]],\n",
    "            name=_df.ip.iloc[0],\n",
    "            showlegend=True,\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subtract the First Moment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtract_mean(df):\n",
    "    df[\"x_prime\"] = df[\"x\"] - df[\"x\"].mean()\n",
    "    df[\"y_prime\"] = df[\"y\"] - df[\"y\"].mean()\n",
    "    return df\n",
    "\n",
    "\n",
    "intersection_df = intersection_df.groupby(\"object_id\", group_keys=False).apply(\n",
    "    subtract_mean\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a 2nd Order Polynomial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "intersection_df[\"norm_time\"] = (\n",
    "    intersection_df[\"epoch_time\"] - intersection_df[\"epoch_time\"].min()\n",
    ").dt.total_seconds()\n",
    "\n",
    "\n",
    "def fit_polynomial(df, degree=2):\n",
    "    if len(df) < (degree + 1):\n",
    "        return None\n",
    "\n",
    "    t = df[\"norm_time\"]\n",
    "    y = df[[\"x_prime\", \"y_prime\"]]\n",
    "\n",
    "    return np.polyfit(t, y, degree)\n",
    "\n",
    "\n",
    "polys = (\n",
    "    intersection_df.groupby(\"object_id\", group_keys=True)\n",
    "    .apply(fit_polynomial)\n",
    "    .to_dict()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "# get a random vehicle\n",
    "obj_id = intersection_df.object_id.sample(1).values[0]\n",
    "\n",
    "pred_x = np.polyval(\n",
    "    polys[obj_id][:, 0],\n",
    "    intersection_df.loc[intersection_df[\"object_id\"] == obj_id, \"norm_time\"].values,\n",
    ")\n",
    "pred_y = np.polyval(\n",
    "    polys[obj_id][:, 1],\n",
    "    intersection_df.loc[intersection_df[\"object_id\"] == obj_id, \"norm_time\"].values,\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=intersection_df.loc[intersection_df[\"object_id\"] == obj_id, \"norm_time\"],\n",
    "        y=intersection_df.loc[intersection_df[\"object_id\"] == obj_id, \"x_prime\"],\n",
    "        mode=\"lines\",\n",
    "        opacity=1,\n",
    "        line_color=\"red\",\n",
    "        name=\"x_prime\",\n",
    "        showlegend=True,\n",
    "    )\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=intersection_df.loc[intersection_df[\"object_id\"] == obj_id, \"norm_time\"],\n",
    "        y=pred_x,\n",
    "        mode=\"lines\",\n",
    "        opacity=1,\n",
    "        line_color=\"blue\",\n",
    "        name=\"pred_x\",\n",
    "        showlegend=True,\n",
    "    )\n",
    ")\n",
    "\n",
    "# add the predicted y values\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=intersection_df.loc[intersection_df[\"object_id\"] == obj_id, \"norm_time\"],\n",
    "        y=intersection_df.loc[intersection_df[\"object_id\"] == obj_id, \"y_prime\"],\n",
    "        mode=\"lines\",\n",
    "        opacity=1,\n",
    "        line_color=\"green\",\n",
    "        name=\"y_prime\",\n",
    "        showlegend=True,\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=intersection_df.loc[intersection_df[\"object_id\"] == obj_id, \"norm_time\"],\n",
    "        y=pred_y,\n",
    "        mode=\"lines\",\n",
    "        opacity=1,\n",
    "        line_color=\"orange\",\n",
    "        name=\"pred_y\",\n",
    "        showlegend=True,\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the Difference Between the Start and End Positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def get_total_distance(df):\n",
    "    start_x, start_y = df[[\"x_prime\", \"y_prime\"]].iloc[0]\n",
    "    end_x, end_y = df[[\"x_prime\", \"y_prime\"]].iloc[-1]\n",
    "\n",
    "    return np.sqrt((end_x - start_x) ** 2 + (end_y - start_y) ** 2)\n",
    "\n",
    "\n",
    "distances = intersection_df.groupby(\n",
    "    \"object_id\",\n",
    ").apply(get_total_distance)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Vector of Features\n",
    "\n",
    "$\\left [ \\beta_0, \\beta_1, \\beta_2, \\alpha \\right]$\n",
    "\n",
    "Except my beta is 2x3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = {}\n",
    "cars = {}\n",
    "for k, betas in polys.items():\n",
    "    if betas is not None:\n",
    "        # unpack the betas\n",
    "        ip = k.split(\"_\")[1]\n",
    "        if ip not in vectors:\n",
    "            vectors[ip] = []\n",
    "            cars[ip] = []\n",
    "\n",
    "        vectors[ip].append(np.array([*betas[:, 0], *betas[:, 1], distances[k]]))\n",
    "        # vectors[ip].append(np.array([*betas, distances[k], ]))\n",
    "        cars[ip].append(k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "import numpy.ma as ma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ip, vect in vectors.items():\n",
    "    vectors[ip] = np.array(vect)\n",
    "    cars[ip] = np.array(cars[ip])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack the vectors and normalize them\n",
    "vector_stack = np.vstack([vectors[ip] for ip in vectors])\n",
    "\n",
    "# normalize the vectors\n",
    "vector_stack = (vector_stack - vector_stack.mean(axis=0)) / (vector_stack.std(axis=0))\n",
    "\n",
    "# split the vectors back into the radar groups\n",
    "vectors = {\n",
    "    ip: vector_stack[i * len(vectors[ip]) : (i + 1) * len(vectors[ip])]\n",
    "    for i, ip in enumerate(vectors)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_distance = distance.cdist(\n",
    "    vectors[\"10.160.7.137\"], vectors[\"10.160.7.141\"], \"correlation\"\n",
    ")\n",
    "# mx = ma.masked_array(corr_distance, np.eye(corr_distance.shape[0], dtype=bool))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = dict(\n",
    "    zip(\n",
    "        cars[\"10.160.7.137\"],\n",
    "        cars[\"10.160.7.141\"][corr_distance.argmin(axis=1)],\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "\n",
    "# get a random vehicle\n",
    "obj_id = (\n",
    "    intersection_df.object_id.loc[\n",
    "        intersection_df.object_id.str.contains(\"10.160.7.137\")\n",
    "    ]\n",
    "    .sample(1)\n",
    "    .values[0]\n",
    ")\n",
    "\n",
    "\n",
    "plotted_ips = set()\n",
    "for veh in [obj_id, matches[obj_id]]:\n",
    "    _df = df.filter(pl.col(\"object_id\") == veh).to_pandas()\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=_df.epoch_time,\n",
    "            y=_df.distance_from_tl1,\n",
    "            mode=\"lines\",\n",
    "            opacity=1,\n",
    "            line_color=radar_color_map[_df.ip.iloc[0]],\n",
    "            name=veh,\n",
    "            showlegend=True,\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying Other Methods\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9513575\n",
    "\n",
    "1. Uses OSPA distance & hungarian algorithm to find the best match\n",
    "   1. This seems overly complicated, and still doesn't consider time\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My Own Method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_df = gpd.read_file(\"overlap_zones/137_handoff.geojson\")\n",
    "\n",
    "# convert to utm\n",
    "line_df = line_df.to_crs(line_df.estimate_utm_crs())\n",
    "\n",
    "# convert from multilinestring to polygon\n",
    "line_df[\"geometry\"] = line_df[\"geometry\"].convex_hull\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import LineString\n",
    "\n",
    "# create a grouped geodataframe for vehicles with their trajectories as a linestring\n",
    "res = (\n",
    "    intersection_df.groupby(\"object_id\")\n",
    "    .apply(lambda x: LineString(x[[\"x\", \"y\"]].values))\n",
    "    .to_frame(\"geometry\")\n",
    ")\n",
    "res[\"epoch_time\"] = intersection_df.groupby(\"object_id\").apply(\n",
    "    lambda x: x[\"epoch_time\"].values\n",
    ")\n",
    "res[\"ip\"] = intersection_df.groupby(\"object_id\")[\"ip\"].transform(\"first\")\n",
    "#         'epoch_time': lambda x: x['epoch_time'].values,\n",
    "#         'ip': lambda x: x['ip'].values,\n",
    "\n",
    "#     }\n",
    "# )\n",
    "\n",
    "\n",
    "res = gpd.GeoDataFrame(res, geometry=\"geometry\", crs=line_df.crs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[\"xy1\"] = res.geometry.intersection(line_df.geometry.iloc[0])\n",
    "res[\"xy2\"] = res.geometry.intersection(line_df.geometry.iloc[1])\n",
    "res[\"xy3\"] = res.geometry.intersection(line_df.geometry.iloc[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sumo-uc-2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
